{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import load_dataset as ldts\n",
    "from tools import feature_name_gen as fng\n",
    "import tools.feature_extraction as fe\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets_train/fake/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ACA\\Assignment1\\creating_customDTS.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ACA/Assignment1/creating_customDTS.ipynb#ch0000003?line=0'>1</a>\u001b[0m dts_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdatasets_train/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ACA/Assignment1/creating_customDTS.ipynb#ch0000003?line=2'>3</a>\u001b[0m imgs, labels \u001b[39m=\u001b[39m ldts\u001b[39m.\u001b[39;49mload_dataset(dts_path)\n",
      "File \u001b[1;32md:\\ACA\\Assignment1\\tools\\load_dataset.py:17\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=13'>14</a>\u001b[0m fakePath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfake/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=14'>15</a>\u001b[0m realPath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mreal/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=16'>17</a>\u001b[0m fake_imgs \u001b[39m=\u001b[39m load_imgs(path\u001b[39m+\u001b[39;49mfakePath)\n\u001b[0;32m     <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=19'>20</a>\u001b[0m fake_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(fake_imgs), \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m     <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=20'>21</a>\u001b[0m real_imgs \u001b[39m=\u001b[39m load_imgs(path\u001b[39m+\u001b[39mrealPath)\n",
      "File \u001b[1;32md:\\ACA\\Assignment1\\tools\\load_dataset.py:7\u001b[0m, in \u001b[0;36mload_imgs\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_imgs\u001b[39m(path):\n\u001b[0;32m      <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=5'>6</a>\u001b[0m     imgs \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=6'>7</a>\u001b[0m     path_list \u001b[39m=\u001b[39m listdir(path)\n\u001b[0;32m      <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m img_path \u001b[39min\u001b[39;00m path_list:\n\u001b[0;32m      <a href='file:///d%3A/ACA/Assignment1/tools/load_dataset.py?line=8'>9</a>\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path\u001b[39m+\u001b[39mimg_path, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets_train/fake/'"
     ]
    }
   ],
   "source": [
    "dts_path = 'dataset_train/'\n",
    "\n",
    "imgs, labels = ldts.load_dataset(dts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMG\n",
    "Img (784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 784)\n",
      "Dataframe shape:  (30, 784)\n"
     ]
    }
   ],
   "source": [
    "# print(imgs[0])\n",
    "S_images = []\n",
    "for img in imgs:\n",
    "    S_images.append(fe.feature_SerializedImg(img=img))\n",
    "\n",
    "S_images = np.array(S_images)\n",
    "print(\"Data shape: \",S_images.shape)\n",
    "\n",
    "df = pd.DataFrame(S_images) # Images\n",
    "df.columns = fng.gen_name(\"img\", 784)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract New Features and add to Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Color\n",
    "Img (784) | Mean Color (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30,)\n",
      "Dataframe shape:  (30, 785)\n"
     ]
    }
   ],
   "source": [
    "cMean = []\n",
    "for img in imgs:\n",
    "    cMean.append(fe.feature_colorMean(img=img))\n",
    "\n",
    "cMean = np.array(cMean)\n",
    "print(\"Data shape: \", cMean.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(cMean)\n",
    "temp_df.columns = [\"MeanColor\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SumImg\n",
    "Img (784) | Mean Color (1) | SumImg (57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 57)\n",
      "RangeIndex(start=0, stop=57, step=1)\n",
      "Dataframe shape:  (30, 842)\n"
     ]
    }
   ],
   "source": [
    "SumImg = []\n",
    "for img in imgs:\n",
    "    SumImg.append(fe.feature_SumImg(img=img))\n",
    "\n",
    "SumImg = np.array(SumImg)\n",
    "print(\"Data shape: \", SumImg.shape)\n",
    "\n",
    "\n",
    "temp_df = pd.DataFrame(SumImg)\n",
    "print(temp_df.columns)\n",
    "temp_df.columns = fng.gen_name(\"rowSum\", 28)+fng.gen_name(\"colSum\", 28)+[\"allSum\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ColorHistogram\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 256)\n",
      "Dataframe shape:  (30, 1098)\n"
     ]
    }
   ],
   "source": [
    "ColorHistogram = []\n",
    "for img in imgs:\n",
    "    ColorHistogram.append(fe.feature_colorHistogram(img=img))\n",
    "\n",
    "ColorHistogram = np.array(ColorHistogram)\n",
    "ColorHistogram = np.squeeze(ColorHistogram)\n",
    "print(\"Data shape: \", ColorHistogram.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(ColorHistogram)\n",
    "temp_df.columns = fng.gen_name(\"CHistogram\", 256)\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | feature_noise (57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 57)\n",
      "Dataframe shape:  (30, 1155)\n"
     ]
    }
   ],
   "source": [
    "noise = []\n",
    "for img in imgs:\n",
    "    noise.append(fe.feature_noise(img=img))\n",
    "\n",
    "noise = np.array(noise)\n",
    "print(\"Data shape: \", noise.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(noise)\n",
    "temp_df.columns = fng.gen_name(\"rowNoise\", 28)+fng.gen_name(\"colNoise\", 28)+[\"allNoise\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Blur\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | feature_noise (57) | feature_gBlur (784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 784)\n",
      "Dataframe shape:  (30, 1939)\n"
     ]
    }
   ],
   "source": [
    "gBlur = []\n",
    "for img in imgs:\n",
    "    gb = fe.feature_gBlur(img=img)\n",
    "    gBlur.append(fe.feature_SerializedImg(img=gb))\n",
    "\n",
    "gBlur = np.array(gBlur)\n",
    "print(\"Data shape: \", gBlur.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(gBlur)\n",
    "temp_df.columns = fng.gen_name(\"gBlur\", 784)\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Blur Mean\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30,)\n",
      "Dataframe shape:  (30, 1940)\n"
     ]
    }
   ],
   "source": [
    "gBlurMean = []\n",
    "for img in imgs:\n",
    "    gb = fe.feature_gBlur(img=img)\n",
    "    gBlurMean.append(fe.feature_colorMean(img=gb))\n",
    "\n",
    "gBlurMean = np.array(gBlurMean)\n",
    "print(\"Data shape: \", gBlurMean.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(gBlurMean)\n",
    "temp_df.columns = [\"gBlurMean\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Blur Sum\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 57)\n",
      "Dataframe shape:  (30, 1997)\n"
     ]
    }
   ],
   "source": [
    "gBlurSum = []\n",
    "for img in imgs:\n",
    "    gb = fe.feature_gBlur(img=img)\n",
    "    gBlurSum.append(fe.feature_SumImg(img=gb))\n",
    "\n",
    "gBlurSum = np.array(gBlurSum)\n",
    "print(\"Data shape: \", gBlurSum.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(gBlurSum)\n",
    "temp_df.columns = fng.gen_name(\"rowGBlur\", 28) + \\\n",
    "    fng.gen_name(\"colGBlur\", 28)+[\"allGBlur\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Blur\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57) | mBlur (784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 784)\n",
      "Dataframe shape:  (30, 2781)\n"
     ]
    }
   ],
   "source": [
    "mBlur = []\n",
    "for img in imgs:\n",
    "    mb = fe.feature_medianBlur(img=img)\n",
    "    mBlur.append(fe.feature_SerializedImg(img=mb))\n",
    "\n",
    "mBlur = np.array(mBlur)\n",
    "print(\"Data shape: \", mBlur.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(mBlur)\n",
    "temp_df.columns = fng.gen_name(\"mBlur\", 784)\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Blur Mean\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57) | mBlur (784) | mBlurMean (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30,)\n",
      "Dataframe shape:  (30, 2782)\n"
     ]
    }
   ],
   "source": [
    "mBlurMean = []\n",
    "for img in imgs:\n",
    "    gb = fe.feature_medianBlur(img=img)\n",
    "    mBlurMean.append(fe.feature_colorMean(img=mb))\n",
    "\n",
    "mBlurMean = np.array(mBlurMean)\n",
    "print(\"Data shape: \", mBlurMean.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(gBlurMean)\n",
    "temp_df.columns = [\"mBlurMean\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Blur Sum\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57) | mBlur (784) | mBlurMean (1) | mBlurSum (57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 57)\n",
      "Dataframe shape:  (30, 2839)\n"
     ]
    }
   ],
   "source": [
    "mBlurSum = []\n",
    "for img in imgs:\n",
    "    mb = fe.feature_medianBlur(img=img)\n",
    "    mBlurSum.append(fe.feature_SumImg(img=mb))\n",
    "\n",
    "mBlurSum = np.array(mBlurSum)\n",
    "print(\"Data shape: \", mBlurSum.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(mBlurSum)\n",
    "temp_df.columns = fng.gen_name(\"rowMBlur\", 28) + \\\n",
    "    fng.gen_name(\"colMBlur\", 28)+[\"allMBlur\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canny Edge Detector\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57) | mBlur (784) | mBlurMean (1) | mBlurSum (57) | Canny (784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 784)\n",
      "Dataframe shape:  (30, 3623)\n"
     ]
    }
   ],
   "source": [
    "canny = []\n",
    "for img in imgs:\n",
    "    cannyDet = fe.feature_cannyEdge(img=img)\n",
    "    canny.append(fe.feature_SerializedImg(img=cannyDet))\n",
    "\n",
    "canny = np.array(canny)\n",
    "print(\"Data shape: \", canny.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(canny)\n",
    "temp_df.columns = fng.gen_name(\"Canny\", 784)\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canny Edge Detector Mean\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57) | mBlur (784) | mBlurMean (1) | mBlurSum (57) | Canny (784) | CannyMean (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30,)\n",
      "Dataframe shape:  (30, 3624)\n"
     ]
    }
   ],
   "source": [
    "cannyMean = []\n",
    "for img in imgs:\n",
    "    cM = fe.feature_cannyEdge(img=img)\n",
    "    cannyMean.append(fe.feature_colorMean(img=cM))\n",
    "\n",
    "cannyMean = np.array(cannyMean)\n",
    "print(\"Data shape: \", cannyMean.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(cannyMean)\n",
    "temp_df.columns = [\"CannyMean\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canny Edge Detector Sum\n",
    "Img (784) | Mean Color (1) | SumImg (57) | ColorHistogram (256) | noise (57) | gBlur (784) | gBlurMean (1) | gBlurSum (57) | mBlur (784) | mBlurMean (1) | mBlurSum (57) | Canny (784) | CannyMean (1) | CannySum (57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 57)\n",
      "Dataframe shape:  (30, 3681)\n"
     ]
    }
   ],
   "source": [
    "cannySum = []\n",
    "for img in imgs:\n",
    "    cS = fe.feature_cannyEdge(img=img)\n",
    "    cannySum.append(fe.feature_SumImg(img=cS))\n",
    "\n",
    "cannySum = np.array(cannySum)\n",
    "print(\"Data shape: \", cannySum.shape)\n",
    "\n",
    "temp_df = pd.DataFrame(cannySum)\n",
    "temp_df.columns = fng.gen_name(\"rowCanny\", 28) + \\\n",
    "    fng.gen_name(\"colCanny\", 28)+[\"allCanny\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (30, 1)\n",
      "Dataframe shape:  (30, 3682)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape: \", labels.shape)\n",
    "temp_df = pd.DataFrame(labels)\n",
    "temp_df.columns = [\"Label\"]\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "print(\"Dataframe shape: \", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('p_dataset_train.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ec01e77c96c9171e407cfb31889f67e9dc04066a09f3d98ca88bf47e6432c95"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ACA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
