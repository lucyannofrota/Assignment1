{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torch.nn.functional as fun\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import load_dataset\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_dataset('dts/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_breast_cancer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# data = load_breast_cancer()\n",
    "# x = data['data']\n",
    "# y = data['target']\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=1)\n",
    "\n",
    "# train, test = train_test_split(data, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import dataset\n",
    "training_set = dataset(x_train, y_train)\n",
    "testing_set = dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=32, shuffle=True)\n",
    "testing_loader=DataLoader(testing_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(network, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=n_features, out_features=int(n_features/2))\n",
    "        self.linear2 = nn.Linear(in_features=int(n_features/2), out_features=n_features)\n",
    "        self.classification = nn.Linear(in_features=n_features, out_features=1)\n",
    "    def activation(self, f):\n",
    "        return fun.relu(f)\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.linear1(x))\n",
    "        x = self.activation(self.linear2(x))\n",
    "        x = self.classification(x)\n",
    "        x = fun.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(number_of_epochs, net, training_loader):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = opt.SGD(params=net.parameters(), lr=1.7e-2)# momentum=0.65, weight_decay=0.9)\n",
    "    running_loss = 0\n",
    "    net.train()\n",
    "    for epoch in range(number_of_epochs):\n",
    "        for batch_id, data in enumerate(training_loader):\n",
    "            imgs, labels = data\n",
    "            y_pred = net(imgs)\n",
    "\n",
    "            # print(y_pred)\n",
    "            loss = criterion(y_pred, labels.reshape(-1, 1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if batch_id % 1000 == 99: # prints every 1000 batchs\n",
    "                print('[%d, %5d] loss: %.5f' % (epoch + 1, batch_id + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def test(testing_loader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(2))\n",
    "    class_total = list(0. for i in range(2))\n",
    "    net.eval()\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_id, data in enumerate(testing_loader):\n",
    "            imgs, labels = data\n",
    "            predicted = net(imgs)\n",
    "            \n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            aux = []\n",
    "            \n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i] > 0.5:\n",
    "                    aux.append(1)\n",
    "                else: aux.append(0)\n",
    "            for p in range(len(aux)):\n",
    "                if labels[p] == aux[    p]:\n",
    "                    if labels[p] == 1:\n",
    "                        class_correct[0] += 1\n",
    "                    else:\n",
    "                        class_correct[1] += 1\n",
    "                if labels[p] == 1:\n",
    "                    class_total[0] += 1\n",
    "                else:\n",
    "                    class_total[1] += 1\n",
    "        \n",
    "        return class_correct, class_total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.00070\n",
      "[2,   100] loss: 0.00028\n",
      "[3,   100] loss: 0.00025\n",
      "[4,   100] loss: 0.00007\n",
      "[5,   100] loss: 0.00007\n",
      "[6,   100] loss: 0.00003\n",
      "[7,   100] loss: 0.00006\n",
      "[8,   100] loss: 0.00001\n",
      "[9,   100] loss: 0.00002\n",
      "[10,   100] loss: 0.00000\n",
      "[11,   100] loss: 0.00002\n",
      "[12,   100] loss: 0.00002\n",
      "[13,   100] loss: 0.00005\n",
      "[14,   100] loss: 0.00003\n",
      "[15,   100] loss: 0.00000\n",
      "[16,   100] loss: 0.00000\n",
      "[17,   100] loss: 0.00000\n",
      "[18,   100] loss: 0.00000\n",
      "[19,   100] loss: 0.00000\n",
      "[20,   100] loss: 0.00000\n"
     ]
    }
   ],
   "source": [
    "model = network(x_train.shape[1])\n",
    "train(number_of_epochs=20, net=model, training_loader=training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.98225\n"
     ]
    }
   ],
   "source": [
    "class_correct, class_total = test(testing_loader, model)\n",
    "print(\"Acc: \" + str((class_correct[0] + class_correct[1])/(class_total[0] + class_total[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\ACA\\lib\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from lib.data import load_dataset\n",
    "\n",
    "x_test = load_dataset('dts/test.csv', test_only=True)\n",
    "testing_set_ = dataset(x_test, np.zeros(x_test.shape))\n",
    "x_test_loader = DataLoader(testing_set_, batch_size=32)\n",
    "\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_id, data in enumerate(x_test_loader):\n",
    "        imgs, labels = data\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            \n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] > 0.5:\n",
    "                y_pred.append(1)\n",
    "            else: y_pred.append(0)\n",
    "y_pred = np.array(y_pred)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.DataFrame(data={\n",
    "        \"Id\": range(y_pred.shape[0]),\n",
    "        \"Category\": y_pred.astype(int)\n",
    "    }, index=None)\n",
    "\n",
    "result.to_csv(\"result.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8abdb4fc4f46750fd86fb77f239c6ff70e435aa065a37b0dbbb4fe7fbbc184de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ACA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
