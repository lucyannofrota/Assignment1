{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train Set\n",
    "\n",
    "features (3681) | labels (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Columns: 3684 entries, Unnamed: 0 to Label\n",
      "dtypes: bool(1), float64(3682), int64(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import cudf\n",
    "import cupy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df = pd.read_feather(\"dts/np_dataset_train.ftr\")\n",
    "df = pd.read_csv(\"dts/np_dataset_train.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32000 entries, 31392 to 23720\n",
      "Columns: 3684 entries, Unnamed: 0 to Label\n",
      "dtypes: bool(1), float64(3682), int64(1)\n",
      "memory usage: 899.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8000 entries, 2727 to 32354\n",
      "Columns: 3684 entries, Unnamed: 0 to Label\n",
      "dtypes: bool(1), float64(3682), int64(1)\n",
      "memory usage: 224.9 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rs = 2\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=rs)\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "from cuml.svm import SVC\n",
    "\n",
    "clf = SVC(random_state = rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 3683)\n",
      "(32000,)\n"
     ]
    }
   ],
   "source": [
    "x = cudf.DataFrame(train.iloc[:, :-1])\n",
    "# y = (train.iloc[:, -1])\n",
    "\n",
    "y = cupy.array(train.iloc[:, -1])\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      " Acc: 1.00, ROC: 1.00\n",
      " PRE: 1.00, REC: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "roc = roc_auc_score(test.iloc[:, -1], y_pred)\n",
    "pre = precision_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "rec = recall_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "\n",
    "\n",
    "print(\"Metrics: \\n Acc: {acc:.2f}, ROC: {roc:.2f}\\n PRE: {pre:.2f}, REC: {rec:.2f}\".format(acc=accuracy,roc=roc,pre=pre,rec=rec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SC graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "rocs = []\n",
    "pres = []\n",
    "recs = []\n",
    "\n",
    "\n",
    "for rs in range(100):\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=rs)\n",
    "\n",
    "    clf = SVC(random_state=rs)\n",
    "\n",
    "    x = cudf.DataFrame(train.iloc[:, :-1])\n",
    "    y = cupy.array(train.iloc[:, -1])\n",
    "\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test.iloc[:, :-1])\n",
    "\n",
    "    accuracy = accuracy_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "    accs.append(accuracy)\n",
    "    roc = roc_auc_score(test.iloc[:, -1], y_pred)\n",
    "    rocs.append(roc)\n",
    "    pre = precision_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "    pres.append(pre)\n",
    "    rec = recall_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "    recs.append(rec)\n",
    "\n",
    "    print(\"{i}/100\".format(i=rs+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: (0.998750,1.0|0.999829)\n",
      "Roc: (0.998751,1.0|0.999829)\n",
      "Pre: (0.997504,1.0|0.999832)\n",
      "Rec: (0.997532,1.0|0.999826)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# plt.stairs(accs)\n",
    "\n",
    "# npAccs = np.array(accs)\n",
    "# npRocs = np.array(rocs)\n",
    "# npPres = np.array(pres)\n",
    "# npRecs = np.array(recs)\n",
    "\n",
    "def min_max(name,array):\n",
    "    a = np.array(array)\n",
    "    print(\"{name}: ({min:.6f},{max:.1f}|{mean:.6f})\".format(\n",
    "        name=name, min=np.min(a), max=np.max(a), mean=np.mean(a)))\n",
    "\n",
    "min_max(\"Acc\",accs)\n",
    "min_max(\"Roc\", rocs)\n",
    "min_max(\"Pre\", pres)\n",
    "min_max(\"Rec\", recs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ec01e77c96c9171e407cfb31889f67e9dc04066a09f3d98ca88bf47e6432c95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
