{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torch.nn.functional as fun\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import load_dataset\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_dataset('dts/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import dataset\n",
    "training_set = dataset(x_train, y_train)\n",
    "testing_set = dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "testing_loader=DataLoader(testing_set, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(network, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=n_features, out_features=int(n_features/2))\n",
    "        self.linear2 = nn.Linear(in_features=int(n_features/2), out_features=n_features)\n",
    "        self.classification = nn.Linear(in_features=n_features, out_features=2)\n",
    "    def activation(self, f):\n",
    "        return fun.relu(f)\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.linear1(x))\n",
    "        x = self.activation(self.linear2(x))\n",
    "        x = self.classification(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(number_of_epochs, net, training_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = opt.SGD(params=net.parameters(), lr=1e-6, momentum=0.65, weight_decay=0.9)\n",
    "    running_loss = 0\n",
    "    for epoch in range(number_of_epochs):\n",
    "        for batch_id, data in enumerate(training_loader):\n",
    "            imgs, labels = data\n",
    "            y_pred = net(imgs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_id % 1000 == 999: # prints every 1000 batchs\n",
    "                print('[%d, %5d] loss: %.5f' % (epoch + 1, batch_id + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def test(testing_loader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(2))\n",
    "    class_total = list(0. for i in range(2))\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_id, data in enumerate(testing_loader):\n",
    "            imgs, labels = data\n",
    "            outputs = net(imgs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            for p in range(len(predicted)):\n",
    "                if labels[p] == predicted[p]:\n",
    "                    if labels[p] == 1:\n",
    "                        class_correct[0] += 1\n",
    "                    else:\n",
    "                        class_correct[1] += 1\n",
    "                if labels[p] == 1:\n",
    "                    class_total[0] += 1\n",
    "                else:\n",
    "                    class_total[1] += 1\n",
    "        return class_correct, class_total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\GitHub\\Assignment1\\docker_m\\notebooks\\nn.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/Assignment1/docker_m/notebooks/nn.ipynb#ch0000008?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m network(x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/GitHub/Assignment1/docker_m/notebooks/nn.ipynb#ch0000008?line=1'>2</a>\u001b[0m train(number_of_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, net\u001b[39m=\u001b[39mmodel, training_loader\u001b[39m=\u001b[39mtraining_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "model = network(x_train.shape[1])\n",
    "train(number_of_epochs=10, net=model, training_loader=training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.871\n"
     ]
    }
   ],
   "source": [
    "class_correct, class_total = test(testing_loader, model)\n",
    "print(\"Acc: \" + str((class_correct[0] + class_correct[1])/(class_total[0] + class_total[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import load_dataset\n",
    "\n",
    "x_test = load_dataset('dts/test.csv', test_only=True)\n",
    "testing_set_ = dataset(x_test, np.zeros(x_test.shape))\n",
    "x_test_loader = DataLoader(testing_set_, batch_size=4)\n",
    "\n",
    "y_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_id, data in enumerate(x_test_loader):\n",
    "        imgs, labels = data\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for i in predicted:\n",
    "            y_pred.append(i)\n",
    "y_pred = np.array(y_pred)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.DataFrame(data={\n",
    "        \"Id\": range(y_pred.shape[0]),\n",
    "        \"Category\": y_pred.astype(int)\n",
    "    }, index=None)\n",
    "\n",
    "result.to_csv(\"result.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8abdb4fc4f46750fd86fb77f239c6ff70e435aa065a37b0dbbb4fe7fbbc184de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ACA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
