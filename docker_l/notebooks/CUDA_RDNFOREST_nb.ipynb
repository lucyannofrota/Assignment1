{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train Set\n",
    "\n",
    "features (3681) | labels (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Columns: 3684 entries, Unnamed: 0 to Label\n",
      "dtypes: bool(1), float64(3682), int64(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import cudf\n",
    "import cupy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df = pd.read_feather(\"dts/np_dataset_train.ftr\")\n",
    "df = pd.read_csv(\"dts/np_dataset_train.csv\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32000 entries, 31392 to 23720\n",
      "Columns: 3684 entries, Unnamed: 0 to Label\n",
      "dtypes: bool(1), float64(3682), int64(1)\n",
      "memory usage: 899.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8000 entries, 2727 to 32354\n",
      "Columns: 3684 entries, Unnamed: 0 to Label\n",
      "dtypes: bool(1), float64(3682), int64(1)\n",
      "memory usage: 224.9 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rs = 2\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=rs)\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier as tree_classifier\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class random_forest():\n",
    "    def __init__(self, number_of_trees=1, number_of_iteractions=1, max_depth=1, random_state=1):\n",
    "        self.iteractions = number_of_iteractions\n",
    "        self.number_of_trees = number_of_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = []\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def bootstrap(self, x_samples):\n",
    "        \"\"\" Create subsets of the input, and returns the indexes \n",
    "            from the original sample.\"\"\"\n",
    "        index = []\n",
    "\n",
    "        sample_length = len(x_samples)\n",
    "        np.random.RandomState(self.random_state)\n",
    "        for i in range(self.number_of_trees):\n",
    "            index.append(np.random.randint(0, sample_length, [\n",
    "                         1, sample_length]))\n",
    "        return index\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for tree in self.forest:\n",
    "            y.append(tree.predict(X))\n",
    "        mode_ = stats.mode(y, axis=0)\n",
    "        mode_ = np.transpose(mode_[0])\n",
    "        return mode_\n",
    "\n",
    "    def fit(self, x_samples, y_samples):\n",
    "        idx = self.bootstrap(x_samples)\n",
    "\n",
    "        for t in range(self.number_of_trees):\n",
    "            tree = tree_classifier(\n",
    "                criterion=\"gini\", max_depth=self.max_depth, random_state=self.random_state)\n",
    "            tree.fit(x_samples[flatten(idx[t])], y_samples[flatten(idx[t])])\n",
    "            self.forest.append(tree)\n",
    "\n",
    "    # def train(self, x_samples, y_samples):\n",
    "    #     self.bagging(x_samples, y_samples)\n",
    "\n",
    "\n",
    "def flatten(t):\n",
    "    return [item for item in t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# from cuml.svm import SVC\n",
    "# import random_forest as rf\n",
    "\n",
    "clf = random_forest(number_of_trees=1, number_of_iteractions=1, max_depth=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 3683)\n",
      "(32000,)\n"
     ]
    }
   ],
   "source": [
    "# x = cudf.DataFrame(train.iloc[:, :-1])\n",
    "# y = cupy.array(train.iloc[:, -1])\n",
    "\n",
    "x = pd.DataFrame(train.iloc[:, :-1])\n",
    "y = np.array(train.iloc[:, -1])\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([(8209, 17588, 25938, 14269, 8517, 25798, 30979, 28442, 11185, 20106, 13329, 14279, 27781, 14505, 17431, 24632, 12553, 9122, 5545, 16306, 14905, 16768, 18025, 225, 11379, 25692, 31219, 19794, 8382, 11756, 14859, 29817, 14246, 3931, 18911, 17425, 4224, 12339, 6729, 21812, 22665, 10159, 14147, 9632, 20064, 19999, 11240, 22850, 27496, 1219, 31361, 30935, 13089, 3510, 455, 20428, 29361, 17444, 4252, 28317, 27492, 6622, 20278, 26774, 29033, 29098, 16051, 4303, 26787, 22523, 2455, 14611, 25673, 7544, 26780, 26486, 31115, 1683, 15265, 22987, 12137, 17404, 3120, 3707, 5615, 30357, 16638, 3301, 9913, 10870, 25404, 2709, 26353, 2390, 27565, 2852, 6287, 1115, 19728, 16294, ...)], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8c045d1fe425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-fc710e088e02>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_samples, y_samples)\u001b[0m\n\u001b[1;32m     40\u001b[0m             tree = tree_classifier(\n\u001b[1;32m     41\u001b[0m                 criterion=\"gini\", max_depth=self.max_depth, random_state=self.random_state)\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([(8209, 17588, 25938, 14269, 8517, 25798, 30979, 28442, 11185, 20106, 13329, 14279, 27781, 14505, 17431, 24632, 12553, 9122, 5545, 16306, 14905, 16768, 18025, 225, 11379, 25692, 31219, 19794, 8382, 11756, 14859, 29817, 14246, 3931, 18911, 17425, 4224, 12339, 6729, 21812, 22665, 10159, 14147, 9632, 20064, 19999, 11240, 22850, 27496, 1219, 31361, 30935, 13089, 3510, 455, 20428, 29361, 17444, 4252, 28317, 27492, 6622, 20278, 26774, 29033, 29098, 16051, 4303, 26787, 22523, 2455, 14611, 25673, 7544, 26780, 26486, 31115, 1683, 15265, 22987, 12137, 17404, 3120, 3707, 5615, 30357, 16638, 3301, 9913, 10870, 25404, 2709, 26353, 2390, 27565, 2852, 6287, 1115, 19728, 16294, ...)], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      " Acc: 1.00, ROC: 1.00\n",
      " PRE: 1.00, REC: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "roc = roc_auc_score(test.iloc[:, -1], y_pred)\n",
    "pre = precision_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "rec = recall_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "\n",
    "\n",
    "print(\"Metrics: \\n Acc: {acc:.2f}, ROC: {roc:.2f}\\n PRE: {pre:.2f}, REC: {rec:.2f}\".format(acc=accuracy,roc=roc,pre=pre,rec=rec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SC graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs = []\n",
    "# rocs = []\n",
    "# pres = []\n",
    "# recs = []\n",
    "\n",
    "\n",
    "# for rs in range(100):\n",
    "#     train, test = train_test_split(df, test_size=0.2, random_state=rs)\n",
    "\n",
    "#     clf = SVC(random_state=rs)\n",
    "\n",
    "#     x = cudf.DataFrame(train.iloc[:, :-1])\n",
    "#     y = cupy.array(train.iloc[:, -1])\n",
    "\n",
    "#     clf.fit(x, y)\n",
    "#     y_pred = clf.predict(test.iloc[:, :-1])\n",
    "\n",
    "#     accuracy = accuracy_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "#     accs.append(accuracy)\n",
    "#     roc = roc_auc_score(test.iloc[:, -1], y_pred)\n",
    "#     rocs.append(roc)\n",
    "#     pre = precision_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "#     pres.append(pre)\n",
    "#     rec = recall_score(y_true=test.iloc[:, -1], y_pred=y_pred)\n",
    "#     recs.append(rec)\n",
    "\n",
    "#     print(\"{i}/100\".format(i=rs+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: (0.998750,1.0|0.999829)\n",
      "Roc: (0.998751,1.0|0.999829)\n",
      "Pre: (0.997504,1.0|0.999832)\n",
      "Rec: (0.997532,1.0|0.999826)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # plt.stairs(accs)\n",
    "\n",
    "# # npAccs = np.array(accs)\n",
    "# # npRocs = np.array(rocs)\n",
    "# # npPres = np.array(pres)\n",
    "# # npRecs = np.array(recs)\n",
    "\n",
    "# def min_max(name,array):\n",
    "#     a = np.array(array)\n",
    "#     print(\"{name}: ({min:.6f},{max:.1f}|{mean:.6f})\".format(\n",
    "#         name=name, min=np.min(a), max=np.max(a), mean=np.mean(a)))\n",
    "\n",
    "# min_max(\"Acc\",accs)\n",
    "# min_max(\"Roc\", rocs)\n",
    "# min_max(\"Pre\", pres)\n",
    "# min_max(\"Rec\", recs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ec01e77c96c9171e407cfb31889f67e9dc04066a09f3d98ca88bf47e6432c95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
